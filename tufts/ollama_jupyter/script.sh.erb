#!/usr/bin/env bash

# Unset potential conflicts
unset XDG_RUNTIME_DIR

# ================================
# Find a port for Ollama
# ================================
my_find_port () {
    local host=localhost
    local min_port=49152
    local max_port=65535
    local port_range=($(shuf -i ${min_port}-${max_port}))
    local retries=1

    for ((attempt=0; attempt<=$retries; attempt++)); do
        for port in "${port_range[@]}"; do
            if my_port_used "${host}:${port}"; then
                continue
            fi
            echo "${port}"
            return 0
        done
    done
    echo "‚ùå Failed to find available port in range ${min_port}..${max_port}" >&2
    return 1
}

my_port_used () {
    local port="${1#*:}"
    local host="localhost"
    nc -w 2 "$host" "$port" < /dev/null > /dev/null 2>&1
    return $?
}

my_wait_until_port_used () {
    local port="${1}"
    local time="${2:-30}"
    for ((i=1; i<=time*2; i++)); do
        if my_port_used "${port}"; then
            return 0
        fi
        sleep 0.5
    done
    return 1
}

# ================================
# Start of Script
# ================================
echo "TIMING - Starting main script at: $(date)"

cd "<%= context.working_directory %>" || {
  echo "‚ùå Failed to change to working directory"
  exit 1
}

# Load modules
module purge
module load miniforge/24.7.1-py312
module load singularity

# Find and export Ollama port
export ollama_port="$(my_find_port)"
if [[ -z "$ollama_port" ]]; then
  echo "‚ùå Could not allocate a port for Ollama"
  exit 1
fi

export OLLAMA_HOST="127.0.0.1:${ollama_port}"
export OLLAMA_MODELS="<%= context.modeldir %>"

echo "üì° OLLAMA_HOST: $OLLAMA_HOST"
echo "üìÅ OLLAMA_MODELS: $OLLAMA_MODELS"

# Image and version
IMAGEDIR="/cluster/tufts/ngc/images"
VER="<%= context.version %>"
OLLAMA_SIF="${IMAGEDIR}/ollama_${VER}.sif"

# Start Singularity instance
singularity instance start \
    --nv \
    --env "OLLAMA_HOST=$OLLAMA_HOST" \
    --env "OLLAMA_MODELS=$OLLAMA_MODELS" \
    "$OLLAMA_SIF" \
    "ollama-server-$SLURM_JOB_ID"

singularity run --nv instance://ollama-server-$SLURM_JOB_ID &

singularity instance list --logs

# Capture logs
capture_in_instance_logs () {
  local regex=$1
  local info="$(singularity instance list --logs)"
  if [[ $info =~ $regex ]]; then
    local src="${BASH_REMATCH[1]}"
    if [[ -f $src ]]; then
      local dest="<%= session.staged_root %>/$(basename "$src")"
      echo "Tailing '$src' to '$dest'"
      tail -n +1 -F "$src" > "$dest" &
      return
    fi
  fi
  echo "‚ö†Ô∏è  WARNING: Could not find singularity instance logfile matching '$regex'"
}

capture_in_instance_logs '(\S+err\b)'
capture_in_instance_logs '(\S+out\b)'

# Wait for Ollama to start
echo "Waiting for Ollama server to open port ${ollama_port}..."
echo "TIMING - Starting wait at: $(date)"
if my_wait_until_port_used "127.0.0.1:${ollama_port}" 120; then
  echo "‚úÖ Ollama server is running on port ${ollama_port}!"
  echo "TIMING - Wait ended at: $(date)"
else
  echo "‚ùå Timed out waiting for Ollama to open port ${ollama_port}"
  echo "TIMING - Wait ended at: $(date)"
  exit 1
fi

# Optional: wait extra time for initialization
sleep 5

# Debugging info
module list

# Launch Jupyter
echo "TIMING - Starting Jupyter at: $(date)"

if [[ -z "${CONFIG_FILE}" ]]; then
  echo "‚ùå Error: CONFIG_FILE is not set"
  exit 1
fi

export JUPYTER_PATH="${PWD}/share/jupyter:/cluster/tufts/hpc/tools/anaconda/202105/share/jupyter:/cluster/tufts/hpc/tools/miniforge3/envs/kernels/public"

jupyter notebook --config="${CONFIG_FILE}" 